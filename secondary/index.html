<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SSNJ Formant Speech Synthesizer</title>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 1.5rem;
            background-color: #f8f9fa;
        }
        header {
            text-align: center;
            margin-bottom: 2rem;
        }
        h1 {
            font-size: 2.2rem;
            margin-bottom: 0.5rem;
            color: #2c3e50;
        }
        .subtitle {
            color: #7f8c8d;
            margin-bottom: 1.5rem;
        }
        .tabs {
            display: flex;
            border-bottom: 2px solid #3498db;
            margin-bottom: 1.5rem;
        }
        .tab {
            padding: 0.75rem 1.5rem;
            cursor: pointer;
            background: #ecf0f1;
            border: 1px solid #bdc3c7;
            border-bottom: none;
            border-radius: 5px 5px 0 0;
            margin-right: 0.5rem;
            font-weight: 600;
            transition: all 0.2s;
        }
        .tab.active {
            background: #3498db;
            color: white;
            border-color: #3498db;
        }
        .tab-content {
            display: none;
            padding: 1.5rem;
            background: white;
            border: 1px solid #bdc3c7;
            border-radius: 0 5px 5px 5px;
        }
        .tab-content.active {
            display: block;
        }
        textarea {
            width: 100%;
            height: 280px;
            padding: 1rem;
            font-family: 'Courier New', monospace;
            font-size: 0.95rem;
            border: 2px solid #ddd;
            border-radius: 6px;
            resize: vertical;
            margin-bottom: 1rem;
            line-height: 1.5;
        }
        textarea:focus {
            outline: none;
            border-color: #3498db;
            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);
        }
        .controls {
            display: flex;
            gap: 1rem;
            margin: 1.5rem 0;
            flex-wrap: wrap;
        }
        button {
            padding: 0.75rem 1.5rem;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 6px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s;
            flex: 1;
            min-width: 120px;
        }
        button:hover:not(:disabled) {
            background: #2980b9;
            transform: translateY(-1px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        button:disabled {
            background: #95a5a6;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        button.danger {
            background: #e74c3c;
        }
        button.danger:hover:not(:disabled) {
            background: #c0392b;
        }
        button.secondary {
            background: #95a5a6;
        }
        button.secondary:hover:not(:disabled) {
            background: #7f8c8d;
        }
        .status-bar {
            margin-top: 1.5rem;
            padding: 1rem;
            border-radius: 6px;
            text-align: center;
            font-weight: 500;
            transition: all 0.3s;
        }
        .status-ready {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status-processing {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeeba;
        }
        .status-error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .audio-controls {
            margin-top: 1.5rem;
            padding: 1.25rem;
            background: #f1f8ff;
            border-radius: 8px;
            border: 1px solid #d0e3f1;
        }
        audio {
            width: 100%;
            margin-top: 0.75rem;
        }
        .spec-guide {
            background: #e8f4fc;
            padding: 1rem;
            border-radius: 6px;
            border-left: 4px solid #3498db;
            margin-top: 1rem;
            font-size: 0.95rem;
            line-height: 1.5;
        }
        .spec-guide code {
            background: #fff;
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
        }
        .sample-rate-control {
            background: #f8f9fa;
            padding: 1.25rem;
            border-radius: 8px;
            margin-bottom: 1.25rem;
            border: 1px solid #ddd;
        }
        .sample-rate-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.75rem;
            font-weight: 600;
        }
        .sample-rate-slider {
            width: 100%;
            margin: 0.5rem 0;
        }
        .sample-rate-info {
            display: flex;
            justify-content: space-between;
            font-size: 0.9rem;
            color: #555;
            margin-top: 0.5rem;
        }
        .clamp-warning {
            margin-top: 0.75rem;
            font-size: 0.9rem;
            color: #856404;
            padding: 0.5rem;
            background: #fff3cd;
            border-radius: 4px;
            border-left: 3px solid #ffc107;
        }
        @media (max-width: 600px) {
            .controls {
                flex-direction: column;
            }
            button {
                width: 100%;
            }
            .sample-rate-info {
                flex-direction: column;
                gap: 0.25rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>SSNJ Formant Speech Synthesizer</h1>
        <p class="subtitle">Word ‚Ä¢ Phoneme ‚Ä¢ Spec Mode Synthesis with Dynamic Sample Rate</p>
    </header>

    <div class="tabs">
        <div class="tab active" data-tab="word">üî§ Word Mode</div>
        <div class="tab" data-tab="phoneme">üî§ Phoneme Mode</div>
        <div class="tab" data-tab="spec">üéõÔ∏è Spec Mode</div>
    </div>

    <div id="word-tab" class="tab-content active">
        <textarea id="textInput" placeholder="Enter text to synthesize (e.g., 'hello world')"></textarea>
        <div class="controls">
            <button id="synthesizeBtn">üîä Synthesize</button>
            <button id="playExampleBtn" class="secondary">‚ñ∂Ô∏è Play Example</button>
        </div>
    </div>

    <div id="phoneme-tab" class="tab-content">
        <textarea id="phonemeInput" placeholder="Enter space-separated phonemes (e.g., HH EH L OW W ER L D)"></textarea>
        <div class="spec-guide">
            <strong>Valid Phonemes:</strong> SIL AH AE AA AO EH EY IH IY OW UH UW ER B D G P T K M N NG L R F S SH TH DH V Z ZH W Y HH CH JH<br>
            <strong>Tip:</strong> Start/end with SIL for natural pauses
        </div>
        <div class="controls">
            <button id="synthesizePhonemeBtn">üîä Synthesize</button>
        </div>
    </div>

    <div id="spec-tab" class="tab-content">
        <div class="sample-rate-control">
            <div class="sample-rate-header">
                <span>üéõÔ∏è Sample Rate (SMP): <span id="sampleRateValue">97000</span> Hz</span>
                <span>Nyquist Limit: <strong id="nyquistValue">48500</strong> Hz</span>
            </div>
            <input type="range" id="sampleRateSlider" class="sample-rate-slider" min="8000" max="192000" step="100" value="97000">
            <div class="sample-rate-info">
                <span>8 kHz</span>
                <span>Clamp Limit: <strong id="clampValue">48000</strong> Hz (Nyquist - 500)</span>
                <span>192 kHz</span>
            </div>
            <div class="clamp-warning">
                ‚ö†Ô∏è All pitch values automatically clamped to <strong id="clampDisplay">48000</strong> Hz to prevent aliasing
            </div>
        </div>
        <textarea id="specInput" placeholder="Enter spec format: PHON DUR OVERLAP PITCH0 PITCH1..."># PHONEME  DUR    OVRLP  PITCH_CONTOUR
HH       0.150  0.010  115.0
EH       0.140  0.018  115.0
L        0.120  0.008  115.0
OW       0.160  0.018  115.0 110.0
SIL      0.190  0.008  0.0</textarea>
        <div class="spec-guide">
            <strong>Spec Format:</strong> <code>PHONEME DURATION OVERLAP PITCH0 [PITCH1 PITCH2 ...]</code><br>
            <strong>Fields:</strong><br>
            ‚Ä¢ PHONEME: ARPABET symbol (e.g., HH, EH, SIL)<br>
            ‚Ä¢ DUR: Duration in seconds (0.01-2.0)<br>
            ‚Ä¢ OVRLP: Overlap with next phoneme (0.0-0.5)<br>
            ‚Ä¢ PITCH: One or more pitch values in Hz<br>
            <strong>Lines starting with # are comments</strong><br>
            <strong>Valid phonemes:</strong> SIL AH AE AA AO EH EY IH IY OW UH UW ER B D G P T K M N NG L R F S SH TH DH V Z ZH W Y HH CH JH
        </div>
        <div class="controls">
            <button id="synthesizeSpecBtn">üîä Synthesize</button>
            <button id="loadSongBtn" class="secondary">üéµ Load Example Song</button>
        </div>
    </div>

    <div class="audio-controls">
        <div class="controls">
            <button id="playBtn" disabled>‚ñ∂Ô∏è Play</button>
            <button id="pauseBtn" disabled>‚è∏Ô∏è Pause</button>
            <button id="downloadBtn" disabled>üíæ Download WAV</button>
        </div>
        <audio id="audioPlayer" controls></audio>
    </div>

    <div id="statusBar" class="status-bar status-ready">
        ‚úÖ Ready to synthesize! Select a mode above and enter your input.
    </div>

    <script>
        // DOM Elements
        const tabElements = document.querySelectorAll('.tab');
        const tabContents = document.querySelectorAll('.tab-content');
        const textInput = document.getElementById('textInput');
        const phonemeInput = document.getElementById('phonemeInput');
        const specInput = document.getElementById('specInput');
        const synthesizeBtn = document.getElementById('synthesizeBtn');
        const synthesizePhonemeBtn = document.getElementById('synthesizePhonemeBtn');
        const synthesizeSpecBtn = document.getElementById('synthesizeSpecBtn');
        const playExampleBtn = document.getElementById('playExampleBtn');
        const loadSongBtn = document.getElementById('loadSongBtn');
        const playBtn = document.getElementById('playBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const audioPlayer = document.getElementById('audioPlayer');
        const statusBar = document.getElementById('statusBar');
        const sampleRateSlider = document.getElementById('sampleRateSlider');
        const sampleRateValue = document.getElementById('sampleRateValue');
        const nyquistValue = document.getElementById('nyquistValue');
        const clampValue = document.getElementById('clampValue');
        const clampDisplay = document.getElementById('clampDisplay');

        // State
        let currentAudioUrl = null;
        let currentWavBlob = null;
        let pyodide = null;
        let synthesizeWordFunc = null;
        let synthesizePhonemeFunc = null;
        let synthesizeSpecFunc = null;
        let currentSampleRate = 97000;

        // Tab Switching
        tabElements.forEach(tab => {
            tab.addEventListener('click', () => {
                // Update active tab
                tabElements.forEach(t => t.classList.remove('active'));
                tabContents.forEach(c => c.classList.remove('active'));
                
                tab.classList.add('active');
                const tabName = tab.dataset.tab;
                document.getElementById(`${tabName}-tab`).classList.add('active');
                
                // Update status
                updateStatus(`‚úÖ ${tabName.charAt(0).toUpperCase() + tabName.slice(1)} Mode active`, 'status-ready');
            });
        });

        // Sample Rate Slider
        function updateSampleRateDisplays(value) {
            currentSampleRate = parseInt(value);
            sampleRateValue.textContent = currentSampleRate;
            const nyquist = currentSampleRate / 2;
            const clampLimit = nyquist - 500;
            nyquistValue.textContent = Math.round(nyquist);
            clampValue.textContent = Math.round(clampLimit);
            clampDisplay.textContent = Math.round(clampLimit);
        }

        sampleRateSlider.addEventListener('input', (e) => {
            updateSampleRateDisplays(e.target.value);
        });

        // Initialize displays
        updateSampleRateDisplays(sampleRateSlider.value);

        // Status Updates
        function updateStatus(message, className) {
            statusBar.textContent = message;
            statusBar.className = `status-bar ${className}`;
        }

        // Audio Controls
        playBtn.addEventListener('click', () => {
            if (audioPlayer.src) {
                audioPlayer.play().catch(e => console.error("Play failed:", e));
            }
        });

        pauseBtn.addEventListener('click', () => {
            audioPlayer.pause();
        });

        downloadBtn.addEventListener('click', () => {
            if (!currentWavBlob) return;
            
            const url = URL.createObjectURL(currentWavBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `ssnj_speech_${Date.now()}.wav`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        });

        // Example Buttons
        playExampleBtn.addEventListener('click', () => {
            textInput.value = "hello world this is a test of the formant synthesizer";
            synthesize(textInput.value, 'word');
        });

        loadSongBtn.addEventListener('click', () => {
            specInput.value = `# "Happy Birthday" melody in phonemes
SIL    0.300  0.010  0.0
SIL    0.100  0.010  0.0
S      0.140  0.025  261.6
IH     0.220  0.045  261.6 277.2
N      0.160  0.030  277.2 293.7
TH     0.180  0.035  293.7 311.1
AH     0.240  0.050  311.1 329.6 349.2 349.2
S      0.150  0.028  349.2 329.6
AH     0.260  0.055  329.6 311.1 293.7 293.7
Z      0.170  0.032  293.7 277.2
ER     0.320  0.070  277.2 261.6 246.9 246.9 233.1 233.1
SIL    0.120  0.015  0.0
V      0.150  0.030  233.1
AO     0.240  0.050  233.1 246.9 261.6 261.6
Y      0.180  0.038  261.6 277.2
S      0.160  0.030  277.2 293.7
SIL    0.200  0.020  0.0
AH     1.400  0.400  293.7 293.7 311.1 311.1 349.2 349.2 392.0 392.0
AH     1.500  0.430  392.0 392.0 349.2 349.2 329.6 329.6 311.1 311.1
SIL    0.100  0.012  0.0
S      0.130  0.025  311.1
IH     0.210  0.045  311.1 329.6 349.2
NG     0.230  0.050  349.2 370.0 392.0 392.0
Z      0.140  0.028  392.0 370.0
SIL    0.110  0.018  0.0
D      0.120  0.025  370.0
IH     0.200  0.042  370.0 392.0 415.3
JH     0.150  0.030  415.3 440.0
AH     0.220  0.048  440.0 415.3 392.0 392.0
T      0.130  0.025  392.0 370.0
AH     0.240  0.052  370.0 349.2 329.6 329.6
L      0.170  0.035  329.6 311.1
SIL    0.140  0.020  0.0
D      0.120  0.025  311.1
R      0.160  0.032  311.1 293.7
IY     0.280  0.060  293.7 311.1 329.6 349.2 370.0 370.0
M      0.180  0.038  370.0 349.2
Z      0.210  0.045  349.2 329.6 311.1 311.1
SIL    0.180  0.025  0.0
AH     1.600  0.460  311.1 311.1 293.7 293.7 277.2 277.2 261.6 261.6
ER     1.700  0.480  261.6 277.2 293.7 311.1 329.6 349.2 370.0 392.0
SIL    0.120  0.015  0.0
AH     0.200  0.042  392.0 415.3 440.0
K      0.140  0.028  440.0 415.3
R      0.170  0.035  415.3 392.0
AH     0.220  0.048  392.0 370.0 349.2 349.2
S      0.150  0.030  349.2 329.6
SIL    0.100  0.018  0.0
DH     0.130  0.026  329.6
AH     0.240  0.052  329.6 349.2 370.0 392.0
W      0.160  0.033  392.0 415.3
AY     0.260  0.058  415.3 440.0 466.2 493.9 523.3 523.3
R      0.180  0.038  523.3 493.9
SIL    0.150  0.022  0.0
T      0.120  0.025  493.9
AH     0.210  0.045  493.9 466.2 440.0
N      0.190  0.040  440.0 415.3
AY     0.270  0.062  415.3 440.0 466.2 493.9 523.3 554.4 587.3 587.3
T      0.160  0.033  587.3 554.4
SIL    0.400  0.030  0.0
AH     2.200  0.650  554.4 523.3 493.9 466.2 440.0 415.3 392.0 370.0
ER     2.400  0.700  370.0 392.0 415.3 440.0 466.2 493.9 523.3 554.4
SIL    0.800  0.010  0.0`;
        });

        // Synthesis Functions
        async function synthesize(text, mode) {
            if (!synthesizeWordFunc || !synthesizePhonemeFunc || !synthesizeSpecFunc) {
                alert("Engine not ready yet. Please wait for initialization to complete.");
                return null;
            }

            let func;
            let sampleRate = 97000;

            switch(mode) {
                case 'word': 
                    func = synthesizeWordFunc; 
                    break;
                case 'phoneme': 
                    func = synthesizePhonemeFunc; 
                    break;
                case 'spec': 
                    func = synthesizeSpecFunc;
                    sampleRate = currentSampleRate;
                    break;
                default: 
                    return null;
            }

            try {
                updateStatus("üîä Synthesizing...", "status-processing");
                synthesizeBtn.disabled = true;
                synthesizePhonemeBtn.disabled = true;
                synthesizeSpecBtn.disabled = true;
                playExampleBtn.disabled = true;
                loadSongBtn.disabled = true;
                playBtn.disabled = true;
                pauseBtn.disabled = true;
                downloadBtn.disabled = true;

                const result = mode === 'spec' 
                    ? func(text, sampleRate) 
                    : func(text);
                
                if (!result || result[0] === null) {
                    throw new Error("Synthesis returned null");
                }

                const [wavBytes, detectedMode] = result;
                const wavArray = wavBytes.toJs();
                wavBytes.destroy();

                if (!wavArray || wavArray.length < 44) {
                    throw new Error(`Invalid WAV data: ${wavArray ? wavArray.length : 0} bytes`);
                }

                const wavBuffer = wavArray.buffer.slice(wavArray.byteOffset, wavArray.byteOffset + wavArray.byteLength);
                currentWavBlob = new Blob([wavBuffer], { type: 'audio/wav' });

                if (currentAudioUrl) {
                    URL.revokeObjectURL(currentAudioUrl);
                }

                currentAudioUrl = URL.createObjectURL(currentWavBlob);
                audioPlayer.src = currentAudioUrl;
                audioPlayer.load();

                audioPlayer.onloadeddata = () => {
                    downloadBtn.disabled = false;
                    playBtn.disabled = false;
                    pauseBtn.disabled = false;
                    const modeNames = {
                        'word': 'Word',
                        'phoneme': 'Phoneme',
                        'spec': 'Spec'
                    };
                    const sizeKB = (wavArray.length / 1024).toFixed(1);
                    updateStatus(`‚úÖ ${modeNames[detectedMode] || detectedMode} synthesized! (${sizeKB} KB) @ ${sampleRate} Hz`, "status-ready");
                };

                audioPlayer.onerror = (e) => {
                    console.error("Audio load error:", e);
                    updateStatus(`‚ùå Audio playback failed. Try downloading instead.`, "status-error");
                    downloadBtn.disabled = false;
                };

                return currentAudioUrl;
            } catch (error) {
                console.error("Synthesis error:", error);
                updateStatus(`‚ùå Synthesis failed: ${error.message}`, "status-error");
                return null;
            } finally {
                synthesizeBtn.disabled = false;
                synthesizePhonemeBtn.disabled = false;
                synthesizeSpecBtn.disabled = false;
                playExampleBtn.disabled = false;
                loadSongBtn.disabled = false;
            }
        }

        // Button Event Listeners
        synthesizeBtn.addEventListener('click', () => {
            const text = textInput.value.trim();
            if (!text) {
                updateStatus("‚ö†Ô∏è Please enter text to synthesize", "status-error");
                return;
            }
            synthesize(text, 'word');
        });

        synthesizePhonemeBtn.addEventListener('click', () => {
            const text = phonemeInput.value.trim();
            if (!text) {
                updateStatus("‚ö†Ô∏è Please enter phonemes to synthesize", "status-error");
                return;
            }
            synthesize(text, 'phoneme');
        });

        synthesizeSpecBtn.addEventListener('click', () => {
            const text = specInput.value.trim();
            if (!text) {
                updateStatus("‚ö†Ô∏è Please enter spec data to synthesize", "status-error");
                return;
            }
            synthesize(text, 'spec');
        });

        // Pyodide Initialization
        async function setupPyodide() {
            updateStatus("‚è≥ Initializing Python runtime (this may take 15-30 seconds)...", "status-processing");
            
            try {
                pyodide = await loadPyodide();
                
                await pyodide.loadPackage(['numpy', 'scipy']);
                
                const pythonCode = `
import numpy as np
import scipy.signal as sig
import wave
import re
import json
from typing import Dict, List
from io import BytesIO

# ======================
# JIM.PY CORE CODE (Modified for browser execution)
# ======================

BYTE_TO_PHONEME = {
    0x00: 'SIL', 0x01: 'AH', 0x02: 'AE', 0x03: 'AA', 0x04: 'AO', 0x05: 'EH', 0x06: 'EY',
    0x07: 'IH', 0x08: 'IY', 0x09: 'OW', 0x0A: 'UH', 0x0B: 'UW', 0x0C: 'ER', 0x0D: 'B',
    0x0E: 'D', 0x0F: 'G', 0x10: 'P', 0x11: 'T', 0x12: 'K', 0x13: 'M', 0x14: 'N', 0x15: 'NG',
    0x16: 'L', 0x17: 'R', 0x18: 'F', 0x19: 'S', 0x1A: 'SH', 0x1B: 'TH', 0x1C: 'DH', 0x1D: 'V',
    0x1E: 'Z', 0x1F: 'ZH', 0x20: 'W', 0x21: 'Y', 0x22: 'HH', 0x23: 'CH', 0x24: 'JH',
}

PHONEME_TO_BYTE = {v: k for k, v in BYTE_TO_PHONEME.items()}
VALID_PHONEMES = set(PHONEME_TO_BYTE.keys())
VOWELS = {'AH','AE','AA','AO','EH','EY','IH','IY','OW','UH','UW','ER'}
STOPS = {'P','T','K','B','D','G','CH'}
FRICATIVES_UNVOICED = {'F','S','SH','TH','HH'}
FRICATIVES_VOICED = {'V','Z','ZH','DH'}

class Voice:
    def __init__(self, name: str, description: str = ""):
        self.name = name
        self.description = description
        self.phonemes: Dict[str, Dict] = {}
    
    def get_phoneme_data(self, phoneme: str) -> Dict:
        if phoneme.endswith('_FINAL'):
            base_ph = phoneme.replace('_FINAL', '')
            data = self.phonemes.get(base_ph, self.phonemes.get('SIL', {})).copy()
            if base_ph in VOWELS:
                data['length'] = min(data.get('length', 0.14) * 1.4, 0.35)
            return data
        return self.phonemes.get(phoneme, self.phonemes.get('SIL', {}))
    
    def save(self, filepath: str) -> None:
        pass
    
    @classmethod
    def load(cls, filepath: str) -> 'Voice':
        pass

class DefaultVoice(Voice):
    def __init__(self):
        super().__init__("Default", "Built-in robotic voice")
        self.phonemes = {
            'AH': {'f1': 700, 'f2': 1100, 'f3': 2400, 'f4': 115, 'length': 0.14, 'voiced': True},
            'AE': {'f1': 650, 'f2': 1250, 'f3': 2500, 'f4': 115, 'length': 0.14, 'voiced': True},
            'AA': {'f1': 620, 'f2': 1180, 'f3': 2550, 'f4': 115, 'length': 0.14, 'voiced': True},
            'AO': {'f1': 550, 'f2': 850, 'f3': 2400, 'f4': 115, 'length': 0.14, 'voiced': True},
            'EH': {'f1': 530, 'f2': 1700, 'f3': 2450, 'f4': 115, 'length': 0.14, 'voiced': True},
            'EY': {'f1': 400, 'f2': 2100, 'f3': 2800, 'f4': 115, 'length': 0.14, 'voiced': True},
            'IH': {'f1': 420, 'f2': 1950, 'f3': 2500, 'f4': 115, 'length': 0.14, 'voiced': True},
            'IY': {'f1': 300, 'f2': 2250, 'f3': 3000, 'f4': 115, 'length': 0.14, 'voiced': True},
            'OW': {'f1': 450, 'f2': 900, 'f3': 2350, 'f4': 115, 'length': 0.14, 'voiced': True},
            'UH': {'f1': 400, 'f2': 650, 'f3': 2400, 'f4': 115, 'length': 0.14, 'voiced': True},
            'UW': {'f1': 330, 'f2': 900, 'f3': 2200, 'f4': 115, 'length': 0.14, 'voiced': True},
            'ER': {'f1': 480, 'f2': 1180, 'f3': 1650, 'f4': 115, 'length': 0.14, 'voiced': True},
            'M':  {'f1': 350, 'f2': 1050, 'f3': 2250, 'f4': 115, 'length': 0.12, 'voiced': True},
            'N':  {'f1': 320, 'f2': 1150, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'NG': {'f1': 280, 'f2': 950, 'f3': 2350, 'f4': 115, 'length': 0.12, 'voiced': True},
            'L':  {'f1': 400, 'f2': 1150, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'R':  {'f1': 450, 'f2': 1250, 'f3': 1500, 'f4': 115, 'length': 0.12, 'voiced': True},
            'DH': {'f1': 380, 'f2': 1650, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'V':  {'f1': 380, 'f2': 1550, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'Z':  {'f1': 380, 'f2': 1750, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'ZH': {'f1': 380, 'f2': 1450, 'f3': 2250, 'f4': 115, 'length': 0.12, 'voiced': True},
            'W':  {'f1': 350, 'f2': 700, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'Y':  {'f1': 350, 'f2': 2050, 'f3': 2650, 'f4': 115, 'length': 0.12, 'voiced': True},
            'JH': {'f1': 400, 'f2': 1650, 'f3': 2450, 'f4': 115, 'length': 0.12, 'voiced': True},
            'B':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'D':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'G':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'P':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'T':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'K':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'F':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.125, 'voiced': False},
            'S':  {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.125, 'voiced': False},
            'SH': {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.125, 'voiced': False},
            'TH': {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.125, 'voiced': False},
            'HH': {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.125, 'voiced': False},
            'CH': {'f1': None, 'f2': None, 'f3': None, 'f4': 0, 'length': 0.068, 'voiced': False},
            'SIL': {'f1': 0, 'f2': 0, 'f3': 0, 'f4': 0, 'length': 0.19, 'voiced': 'silence'},
        }

class VoiceRegistry:
    def __init__(self):
        self.voices: Dict[str, Voice] = {'Default': DefaultVoice()}
        self.current_voice: Voice = self.voices['Default']
    
    def set_current_voice(self, name: str) -> bool:
        if name in self.voices:
            self.current_voice = self.voices[name]
            return True
        return False
    
    def list_voices(self) -> Dict[str, Voice]:
        return self.voices

VOICE_REGISTRY = VoiceRegistry()

WORD_MAP = {
    'hello': ['HH', 'EH', 'L', 'AO', 'OW'], 'world': ['W', 'ER', 'L', 'D'], 'test': ['T', 'EH', 'S', 'T'],
    'one': ['W', 'AH', 'N'], 'two': ['T', 'UW'], 'this': ['DH', 'IH', 'S'], 'is': ['IH', 'S'],
    'text': ['T', 'AE', 'K', 'S', 'T'], 'a': ['AH'], 'three': ['TH', 'R', 'IY'], 'four': ['F', 'AO', 'R'],
    'five': ['F', 'AA', 'EY', 'V'], 'six': ['S', 'IH', 'K', 'S'], 'seven': ['S', 'EH', 'V', 'EH', 'N'],
    'eight': ['EY', 'T'], 'nine': ['N', 'AA', 'EY', 'N'], 'ten': ['T', 'EH', 'N'],
    'robot': ['R', 'OW', 'B', 'AH', 'T'], 'voice': ['V', 'AO', 'Y', 'S'], 'i': ['AA', 'EY'],
    'am': ['AH', 'M'], 'and': ['AH', 'N', 'D'], 'single': ['S', 'IH', 'NG', 'G', 'AH', 'L'],
    'yes': ['Y', 'EH', 'S'], 'no': ['N', 'OW'], 'hi': ['HH', 'AA', 'EY'],
    'formant': ['F', 'AO', 'R', 'M', 'AH', 'N', 'T'], 'speech': ['S', 'P', 'IY', 'CH'],
    'synthesis': ['S', 'IH', 'N', 'TH', 'AH', 'S', 'IH', 'S'], 'tts': ['T', 'IY', 'T', 'IY', 'EH', 'S'],
    'computer': ['K', 'AH', 'M', 'P', 'Y', 'UW', 'T', 'ER'], 'please': ['P', 'L', 'IY', 'Z'],
    'thank': ['TH', 'AE', 'NG', 'K'], 'you': ['Y', 'UW'], 'good': ['G', 'UH', 'D'], 'morning': ['M', 'AO', 'R', 'N', 'IH', 'NG'],
    'afternoon': ['AE', 'F', 'T', 'ER', 'N', 'UW', 'N'], 'evening': ['IY', 'V', 'N', 'IH', 'NG'],
    'ship': ['SH', 'IH', 'P'], 'fish': ['F', 'IH', 'SH'], 'think': ['TH', 'IH', 'NG', 'K'],
    'sushi': ['S', 'UW', 'SH', 'IY'], 'zip': ['Z', 'IH', 'P'], 'measure': ['M', 'EH', 'ZH', 'ER'],
    'thin': ['TH', 'IH', 'N'], 'thick': ['TH', 'IH', 'K'], 'thistle': ['TH', 'IH', 'S', 'AH', 'L'],
}

def text_to_phonemes(text: str) -> List[str]:
    text = text.lower().strip()
    text = re.sub(r'[^a-z\s]', '', text)
    words = text.split()
    phoneme_sequence = ['SIL']
    for i, word in enumerate(words):
        phons = WORD_MAP.get(word, ['SIL'])
        phoneme_sequence.extend(phons)
        if i < len(words) - 1:
            phoneme_sequence.append('SIL')
    phoneme_sequence.append('SIL')
    return phoneme_sequence

def parse_phoneme_input(text: str) -> List[str]:
    tokens = text.strip().upper().split()
    phonemes = [tok if tok in VALID_PHONEMES else 'SIL' for tok in tokens]
    if not phonemes:
        return ['SIL', 'SIL']
    if phonemes[0] != 'SIL':
        phonemes.insert(0, 'SIL')
    if phonemes[-1] != 'SIL':
        phonemes.append('SIL')
    return phonemes

def parse_phoneme_spec(text: str, voice: Voice) -> List[Dict]:
    specs = []
    for line_num, line in enumerate(text.splitlines(), 1):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        parts = line.split()
        if len(parts) < 4:
            continue
        ph_name = parts[0].upper()
        if ph_name not in PHONEME_TO_BYTE:
            continue
        try:
            duration = max(0.01, min(2.0, float(parts[1])))
            overlap = max(0.0, min(0.5, float(parts[2])))
            pitch_points = [float(p) for p in parts[3:]]
            if len(pitch_points) > 8:
                pitch_points = pitch_points[:8]
            ph_data = voice.get_phoneme_data(ph_name)
            f1 = ph_data.get('f1', 0.0) or 0.0
            f2 = ph_data.get('f2', 0.0) or 0.0
            f3 = ph_data.get('f3', 0.0) or 0.0
            specs.append({
                'phoneme': ph_name,
                'duration': duration,
                'overlap': overlap,
                'pitch_contour': pitch_points,
                'num_pitch_points': len(pitch_points),
                'f1': f1,
                'f2': f2,
                'f3': f3,
                'voiced': ph_name not in {'SIL','B','D','G','P','T','K','F','S','SH','TH','HH','CH'}
            })
        except ValueError:
            continue
    return specs

def phonemes_to_spec(phonemes: List[str], voice: Voice, pitch_base: float = 115.0) -> List[Dict]:
    specs = []
    for i, ph in enumerate(phonemes):
        ph_data = voice.get_phoneme_data(ph)
        duration = ph_data.get('length', 0.14)
        overlap = 0.018 if ph in VOWELS and i < len(phonemes) - 1 else 0.008
        if ph == 'SIL':
            pitch = [0.0]
        elif ph in VOWELS:
            if i == len(phonemes) - 2:
                pitch = [pitch_base * 0.95, pitch_base * 0.90]
            elif i == 1:
                pitch = [pitch_base * 1.05, pitch_base * 1.10]
            else:
                pitch = [pitch_base]
        else:
            pitch = [pitch_base if ph_data.get('voiced', False) else 0.0]
        f1 = ph_data.get('f1', 0.0) or 0.0
        f2 = ph_data.get('f2', 0.0) or 0.0
        f3 = ph_data.get('f3', 0.0) or 0.0
        specs.append({
            'phoneme': ph,
            'duration': duration,
            'overlap': overlap,
            'pitch_contour': pitch,
            'num_pitch_points': len(pitch),
            'f1': f1,
            'f2': f2,
            'f3': f3,
            'voiced': ph not in {'SIL','B','D','G','P','T','K','F','S','SH','TH','HH','CH'}
        })
    return specs

class FormantSynthesizer:
    def __init__(self, voice: Voice, sample_rate: int):
        self.fs = sample_rate
        self.voice = voice
    
    def generate_glottal_pulse_train_contour(self, duration: float, pitch_contour: List[float]):
        n_samples = int(duration * self.fs)
        signal = np.zeros(n_samples)
        t = 0.0
        if not pitch_contour or all(p == 0 for p in pitch_contour):
            pitch_contour = [115.0]
        num_points = len(pitch_contour)
        while t < duration:
            t_norm = min(1.0, t / duration)
            if num_points == 1:
                f0 = pitch_contour[0]
            else:
                contour_pos = t_norm * (num_points - 1)
                idx_floor = int(contour_pos)
                frac = contour_pos - idx_floor
                if idx_floor >= num_points - 1:
                    f0 = pitch_contour[-1]
                else:
                    f0 = pitch_contour[idx_floor] * (1 - frac) + pitch_contour[idx_floor + 1] * frac
            
            # CRITICAL: CLAMP PITCH TO (Nyquist - 500 Hz) TO PREVENT ALIASING
            nyquist_limit = (self.fs / 2) - 500
            f0 = max(50.0, min(nyquist_limit, f0))
            
            period_samples = self.fs / f0
            pulse_len = int(period_samples * 0.6)
            if pulse_len < 8:
                pulse_len = 8
            pulse = np.zeros(pulse_len)
            open_len = max(4, int(pulse_len * 0.4))
            pulse[:open_len] = -0.5 * (1 - np.cos(np.linspace(0, np.pi, open_len)))
            if pulse_len > open_len:
                close_len = pulse_len - open_len
                pulse[open_len:] = -0.1 * np.exp(-np.linspace(0, 5, close_len))
            start = int(t * self.fs)
            end = min(start + pulse_len, n_samples)
            if end > start:
                signal[start:end] += pulse[:end - start] * 0.6
            t += period_samples / self.fs
        
        peak = np.max(np.abs(signal))
        if peak > 0.1:
            signal = signal * (0.6 / peak)
        return signal
    
    def generate_shaped_noise(self, duration: float, phoneme: str, intensity: float = 0.25):
        n_samples = int(duration * self.fs)
        noise = np.random.randn(n_samples)
        if phoneme in {'S'}:
            b, a = sig.butter(6, [4000/(self.fs/2), 8500/(self.fs/2)], btype='band')
            noise = sig.filtfilt(b, a, noise)
            b2, a2 = sig.butter(4, 6500/(self.fs/2), btype='high')
            noise = sig.filtfilt(b2, a2, noise) * 1.3
        elif phoneme in {'SH', 'ZH'}:
            b, a = sig.butter(5, [2500/(self.fs/2), 6000/(self.fs/2)], btype='band')
            noise = sig.filtfilt(b, a, noise)
        elif phoneme in {'F', 'TH'}:
            b, a = sig.butter(4, 3500/(self.fs/2), btype='low')
            noise = sig.filtfilt(b, a, noise)
        elif phoneme == 'HH':
            b, a = sig.butter(3, 2800/(self.fs/2), btype='low')
            noise = sig.filtfilt(b, a, noise)
            noise += np.random.randn(n_samples) * 0.15
        elif phoneme in {'V', 'DH', 'Z'}:
            b, a = sig.butter(4, 4500/(self.fs/2), btype='low')
            noise = sig.filtfilt(b, a, noise)
            voicing = np.sin(2 * np.pi * 120 * np.arange(n_samples) / self.fs) * 0.15
            noise = noise * 0.85 + voicing * 0.15
        else:
            b, a = sig.butter(4, 7500/(self.fs/2), btype='low')
            noise = sig.filtfilt(b, a, noise)
        peak = np.max(np.abs(noise))
        if peak < 1e-6:
            noise = np.random.randn(n_samples) * intensity * 0.7
            peak = 1.0
        noise = noise * (intensity / peak)
        return noise[:n_samples]
    
    def stable_resonator(self, freq: float, bw: float):
        if freq <= 0:
            return np.array([1.0]), np.array([1.0])
        w0 = 2 * np.pi * freq / self.fs
        bw_rad = max(2 * np.pi * bw / self.fs, 2 * np.pi * 80 / self.fs)
        a1 = -2 * np.exp(-bw_rad/2) * np.cos(w0)
        a2 = np.exp(-bw_rad)
        b0 = np.sqrt(1 - a2)
        return np.array([b0]), np.array([1.0, a1, a2])
    
    def apply_formants_safe(self, signal: np.ndarray, f1: float, f2: float, f3: float) -> np.ndarray:
        b1, b2, b3 = 60, 90, 150
        for freq, bw in [(f1, b1), (f2, b2), (f3, b3)]:
            if freq and freq > 50:
                b, a = self.stable_resonator(freq, bw)
                signal = sig.lfilter(b, a, signal)
        peak = np.max(np.abs(signal))
        if peak > 4.0:
            signal = signal * (3.0 / peak)
        b, a = sig.butter(1, 900/(self.fs/2), btype='high')
        return sig.lfilter(b, a, signal)
    
    def synthesize_phoneme_direct(self, spec: Dict) -> np.ndarray:
        ph = spec['phoneme']
        dur = spec['duration']
        f1, f2, f3 = spec['f1'], spec['f2'], spec['f3']
        pitch_contour = spec['pitch_contour']
        voiced = spec['voiced']
        
        if ph == 'SIL':
            return np.zeros(int(dur * self.fs))
        
        if ph in STOPS:
            n_samples = int(dur * self.fs)
            out = np.zeros(n_samples)
            closure_end = int(n_samples * 0.82)
            burst_start = closure_end
            burst_len = min(200, n_samples - burst_start)
            if burst_len > 30:
                burst_noise = np.random.randn(burst_len)
                if f1 > 50:
                    b1, a1 = self.stable_resonator(f1, 150)
                    b2, a2 = self.stable_resonator(f2, 200)
                    burst_noise = sig.lfilter(b1, a1, burst_noise)
                    burst_noise = sig.lfilter(b2, a2, burst_noise)
                burst_env = np.hanning(burst_len) * 0.6
                out[burst_start:burst_start+burst_len] = burst_noise * burst_env
            
            if ph in {'P', 'T', 'K', 'CH'} and closure_end + burst_len < n_samples:
                aspir_start = burst_start + burst_len
                aspir_len = n_samples - aspir_start
                if aspir_len > 50:
                    aspiration = self.generate_shaped_noise(aspir_len/self.fs, 'HH', intensity=0.18)
                    b, a = sig.butter(2, 800/(self.fs/2), btype='high')
                    aspiration = sig.filtfilt(b, a, aspiration)
                    out[aspir_start:] = aspiration[:aspir_len] * 0.4
            elif ph in {'B', 'D', 'G'} and closure_end + burst_len < n_samples:
                voicing_start = burst_start + int(burst_len * 1.3)
                voicing_len = n_samples - voicing_start
                if voicing_len > 100:
                    voicing = self.generate_glottal_pulse_train_contour(voicing_len/self.fs, [115.0])
                    out[voicing_start:] = voicing[:voicing_len] * 0.35
            return out * 0.85
        
        if not voiced:
            if ph == 'S':
                intensity = 1.28
            elif ph == 'SH':
                intensity = 0.64
            elif ph in {'F', 'TH'}:
                intensity = 0.32
            else:
                intensity = 0.32
            source = self.generate_shaped_noise(dur, ph, intensity=intensity)
            if f1 > 50:
                if ph in {'S', 'SH'}:
                    source = self.apply_formants_safe(source, f1*0.7, f2*0.7, f3*0.7)
                else:
                    source = self.apply_formants_safe(source, f1, f2, f3)
            else:
                source = source * 0.45
            output = source
        else:
            source = self.generate_glottal_pulse_train_contour(dur, pitch_contour)
            if f1 > 50:
                output = self.apply_formants_safe(source, f1, f2, f3)
            else:
                output = source * 0.45
        
        n = len(output)
        env = np.ones(n)
        att = min(0.007, dur * 0.12)
        rel = min(0.018, dur * 0.28)
        att_s = int(att * self.fs)
        rel_s = int(rel * self.fs)
        if att_s > 0:
            env[:att_s] = np.linspace(0, 1, att_s)
        if rel_s > 0:
            env[-rel_s:] = np.linspace(1, 0.05, rel_s)
        output = output * env
        output = np.tanh(output * 1.15) * 0.93
        return output * 0.82
    
    def synthesize_from_specs(self, specs: List[Dict]) -> np.ndarray:
        if not specs:
            return np.zeros(0)
        
        total_duration = 0.0
        for spec in specs:
            total_duration += spec['duration']
        for i in range(len(specs) - 1):
            total_duration -= min(specs[i].get('overlap', 0.0), specs[i]['duration'])
        
        total_samples = int(total_duration * self.fs) + 10
        output = np.zeros(total_samples)
        current_pos = 0
        
        for i, spec in enumerate(specs):
            phoneme_audio = self.synthesize_phoneme_direct(spec)
            phoneme_samples = len(phoneme_audio)
            overlap_dur = spec.get('overlap', 0.0)
            if i == len(specs) - 1:
                overlap_dur = 0.0
            overlap_samples = min(
                int(overlap_dur * self.fs),
                phoneme_samples - 1,
                int(spec['duration'] * self.fs * 0.5)
            )
            end_pos = current_pos + phoneme_samples
            if end_pos > len(output):
                output = np.resize(output, end_pos + 1000)
            output[current_pos:end_pos] += phoneme_audio
            current_pos += (phoneme_samples - overlap_samples)
        
        actual_length = min(current_pos, len(output))
        audio = output[:actual_length]
        audio = np.tanh(audio * 1.25) * 0.94
        b, a = sig.butter(5, 5000/(self.fs/2), btype='low')
        audio = sig.filtfilt(b, a, audio)
        return audio

def generate_wav_bytes(audio: np.ndarray, sr: int) -> bytes:
    audio_int16 = np.clip(audio * 32767, -32768, 32767).astype(np.int16)
    buffer = BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sr)
        wf.writeframes(audio_int16.tobytes())
    return buffer.getvalue()

def synthesize_word_mode(text: str, sample_rate: int = 97000):
    phonemes = text_to_phonemes(text)
    specs = phonemes_to_spec(phonemes, VOICE_REGISTRY.current_voice)
    synth = FormantSynthesizer(VOICE_REGISTRY.current_voice, sample_rate=sample_rate)
    audio = synth.synthesize_from_specs(specs)
    return generate_wav_bytes(audio, sr=sample_rate), "word"

def synthesize_phoneme_mode(text: str, sample_rate: int = 97000):
    phonemes = parse_phoneme_input(text)
    specs = phonemes_to_spec(phonemes, VOICE_REGISTRY.current_voice)
    synth = FormantSynthesizer(VOICE_REGISTRY.current_voice, sample_rate=sample_rate)
    audio = synth.synthesize_from_specs(specs)
    return generate_wav_bytes(audio, sr=sample_rate), "phoneme"

def synthesize_spec_mode(text: str, sample_rate: int = 97000):
    specs = parse_phoneme_spec(text, VOICE_REGISTRY.current_voice)
    synth = FormantSynthesizer(VOICE_REGISTRY.current_voice, sample_rate=sample_rate)
    audio = synth.synthesize_from_specs(specs)
    return generate_wav_bytes(audio, sr=sample_rate), "spec"
`;

                await pyodide.runPythonAsync(pythonCode);
                
                synthesizeWordFunc = pyodide.globals.get('synthesize_word_mode');
                synthesizePhonemeFunc = pyodide.globals.get('synthesize_phoneme_mode');
                synthesizeSpecFunc = pyodide.globals.get('synthesize_spec_mode');
                
                updateStatus("‚úÖ Python engine ready! Select a mode and synthesize speech.", "status-ready");
            } catch (error) {
                console.error("Pyodide initialization failed:", error);
                updateStatus(`‚ùå Initialization failed: ${error.message}`, "status-error");
                alert(`Initialization failed: ${error.message}\nCheck console for details.`);
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            setupPyodide();
            
            // Set default example text
            textInput.value = "hello world this is a test";
            phonemeInput.value = "HH EH L OW W ER L D";
        });
    </script>
</body>
</html>
